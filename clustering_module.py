# Åimdi **`clustering_module.py`** modÃ¼lÃ¼nÃ¼ en gÃ¼ncel haliyle yazÄ±yorum ve ardÄ±ndan yapÄ±lan deÄŸiÅŸiklikleri detaylÄ± olarak aÃ§Ä±klayacaÄŸÄ±m.  

# ğŸš€ **Bu modÃ¼lde hangi yenilikler var?**  
# âœ” **Embedding vektÃ¶rleri kullanÄ±larak makaleler kÃ¼meleme (clustering) iÅŸlemi yapÄ±lÄ±yor.**  
# âœ” **K-Means, DBSCAN ve Agglomerative Clustering gibi farklÄ± algoritmalar destekleniyor.**  
# âœ” **ChromaDBâ€™den alÄ±nan embedding verileri ile doÄŸrudan kÃ¼meleme yapÄ±labiliyor.**  
# âœ” **SQLite ve Redis entegrasyonu saÄŸlandÄ± â€“ kÃ¼meleme sonuÃ§larÄ± kaydedilip Ã¶nbelleÄŸe alÄ±nÄ±yor.**  
# âœ” **Ã‡oklu iÅŸlem desteÄŸi (multiprocessing) ile bÃ¼yÃ¼k veri kÃ¼meleri daha hÄ±zlÄ± iÅŸleniyor.**  

# ---

# ### **ğŸ“Œ `clustering_module.py` ModÃ¼lÃ¼ (Son GÃ¼ncellenmiÅŸ HÃ¢li)**  

# ```python
import numpy as np
import json
import sqlite3
import redis
import chromadb
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from concurrent.futures import ProcessPoolExecutor
from configmodule import config

class ClusteringModule:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.cluster_algorithm = config.CLUSTERING_ALGORITHM.lower()  # kmeans, dbscan, agglomerative
        self.max_clusters = int(config.MAX_CLUSTERS)
        self.max_workers = config.MAX_WORKERS

    def fetch_embeddings(self):
        """
        ChromaDBâ€™den tÃ¼m embedding verilerini Ã§eker.
        """
        collection = self.chroma_client.get_collection(name="embeddings")
        embeddings = collection.get(include=["documents", "metadatas"])
        vectors = [doc["embedding"] for doc in embeddings]
        document_ids = [doc["metadatas"]["document_id"] for doc in embeddings]
        return np.array(vectors), document_ids

    def cluster_documents(self):
        """
        Belirlenen kÃ¼meleme algoritmasÄ±na gÃ¶re embedding verilerini kÃ¼meler.
        """
        vectors, document_ids = self.fetch_embeddings()

        if self.cluster_algorithm == "kmeans":
            cluster_labels = self._kmeans_clustering(vectors)
        elif self.cluster_algorithm == "dbscan":
            cluster_labels = self._dbscan_clustering(vectors)
        elif self.cluster_algorithm == "agglomerative":
            cluster_labels = self._agglomerative_clustering(vectors)
        else:
            raise ValueError(f"Bilinmeyen kÃ¼meleme algoritmasÄ±: {self.cluster_algorithm}")

        clustered_data = [{"document_id": doc_id, "cluster": cluster} for doc_id, cluster in zip(document_ids, cluster_labels)]
        
        self.save_clusters_to_sqlite(clustered_data)
        self.save_clusters_to_redis(clustered_data)

        return clustered_data

    def _kmeans_clustering(self, vectors):
        """
        K-Means algoritmasÄ± ile kÃ¼meleme yapar.
        """
        model = KMeans(n_clusters=self.max_clusters, random_state=42)
        return model.fit_predict(vectors)

    def _dbscan_clustering(self, vectors):
        """
        DBSCAN algoritmasÄ± ile kÃ¼meleme yapar.
        """
        model = DBSCAN(eps=0.5, min_samples=5)
        return model.fit_predict(vectors)

    def _agglomerative_clustering(self, vectors):
        """
        HiyerarÅŸik kÃ¼meleme (Agglomerative Clustering) yapar.
        """
        model = AgglomerativeClustering(n_clusters=self.max_clusters)
        return model.fit_predict(vectors)

    def save_clusters_to_sqlite(self, clustered_data):
        """
        KÃ¼meleme sonuÃ§larÄ±nÄ± SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_clusters (
                document_id TEXT PRIMARY KEY,
                cluster INTEGER
            )
        """)

        for data in clustered_data:
            cursor.execute("INSERT OR REPLACE INTO document_clusters VALUES (?, ?)", 
                           (data["document_id"], data["cluster"]))

        conn.commit()
        conn.close()
        print("ğŸ“Œ KÃ¼meleme sonuÃ§larÄ± SQLite veritabanÄ±na kaydedildi.")

    def save_clusters_to_redis(self, clustered_data):
        """
        KÃ¼meleme sonuÃ§larÄ±nÄ± Redis Ã¶nbelleÄŸine kaydeder.
        """
        for data in clustered_data:
            self.redis_client.setex(f"cluster:{data['document_id']}", 3600, json.dumps(data))
        print("ğŸ“Œ KÃ¼meleme sonuÃ§larÄ± Redis Ã¶nbelleÄŸine kaydedildi.")

    def batch_cluster_documents(self, document_batches):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k veri kÃ¼melerinde kÃ¼meleme sÃ¼recini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.cluster_documents, document_batches)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
clustering_module = ClusteringModule()
# ```

# ---

# ### **ğŸ“Œ YapÄ±lan GÃ¼ncellemeler ve DeÄŸiÅŸiklikler**  

# 1ï¸âƒ£ **ChromaDBâ€™den Embedding Verileri Ã‡ekiliyor:**  
#    - `fetch_embeddings()` fonksiyonu **ChromaDBâ€™den embedding verilerini alÄ±yor.**  
#    - **VektÃ¶rler numpy dizisine Ã§evriliyor ve kÃ¼meleme algoritmasÄ±na gÃ¶nderiliyor.**  

# 2ï¸âƒ£ **KÃ¼meleme AlgoritmalarÄ± Destekleniyor:**  
#    - **K-Means (VarsayÄ±lan)**  
#    - **DBSCAN**  
#    - **Agglomerative Clustering (HiyerarÅŸik KÃ¼meleme)**  
#    - **.env dosyasÄ±ndan hangi algoritmanÄ±n kullanÄ±lacaÄŸÄ± seÃ§ilebiliyor.**  

# 3ï¸âƒ£ **KÃ¼meleme SonuÃ§larÄ± SQLiteâ€™e Kaydediliyor:**  
#    - `save_clusters_to_sqlite()` fonksiyonu **belge kimliÄŸi ve kÃ¼me numarasÄ±nÄ± veritabanÄ±na kaydediyor.**  

# 4ï¸âƒ£ **KÃ¼meleme SonuÃ§larÄ± Redisâ€™e Kaydediliyor:**  
#    - `save_clusters_to_redis()` fonksiyonu **kÃ¼meleme sonuÃ§larÄ±nÄ± Redis Ã¶nbelleÄŸine alÄ±yor.**  
#    - **Ã–nbelleÄŸe alÄ±nan veriler, sorgularÄ±n daha hÄ±zlÄ± yapÄ±lmasÄ±nÄ± saÄŸlÄ±yor.**  

# 5ï¸âƒ£ **Ã‡oklu Ä°ÅŸlem (Multiprocessing) DesteÄŸi:**  
#    - `batch_cluster_documents()` fonksiyonu ile **bÃ¼yÃ¼k veri kÃ¼meleri paralel olarak iÅŸleniyor.**  
#    - **Ã‡ok sayÄ±da makale iÃ§eren bÃ¼yÃ¼k datasetler daha hÄ±zlÄ± kÃ¼meleniyor.**  

# ---

# ğŸ“Œ **SonuÃ§:**  
# âœ… **Embedding vektÃ¶rleri ile ChromaDBâ€™den doÄŸrudan kÃ¼meleme yapÄ±lÄ±yor.**  
# âœ… **K-Means, DBSCAN ve Agglomerative Clustering algoritmalarÄ± destekleniyor.**  
# âœ… **KÃ¼meleme sonuÃ§larÄ± SQLite ve Redisâ€™e kaydediliyor.**  
# âœ… **Ã‡oklu iÅŸlem desteÄŸi eklendi â€“ bÃ¼yÃ¼k veri kÃ¼meleri daha hÄ±zlÄ± iÅŸleniyor.**  

# ğŸš€ **Åimdi bir sonraki modÃ¼le geÃ§elim mi? Hangisini istiyorsun?** ğŸ˜Š