# zapatam6g tarafÄ±ndan paylaÅŸÄ±lan tÃ¼m modÃ¼llerin birleÅŸimi
# Bu dosya, zzzzapata_m6g_tumu.py dosyasÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecektir.
#------
# config_module.py
#------


import os
import logging
import colorlog
from pathlib import Path
from dotenv import load_dotenv
import chromadb

class Config:
    def __init__(self):
        # .env dosyasÄ±nÄ± yÃ¼kle
        load_dotenv()

        # Dizin AyarlarÄ±
        self.KAYNAK_DIZIN = os.getenv("KAYNAK_DIZIN", r"C:\Users\mete\Zotero\zotai")
        self.STORAGE_DIR = Path(os.getenv("STORAGE_DIR", r"C:\Users\mete\Zotero\storage"))
        self.SUCCESS_DIR = Path(os.getenv("SUCCESS_DIR", r"C:\Users\mete\Zotero\zotasistan"))
        self.HEDEF_DIZIN = Path(os.getenv("HEDEF_DIZIN", os.path.join(str(self.KAYNAK_DIZIN), "TemizMetin")))
        self.TEMIZ_TABLO_DIZIN = Path(os.getenv("TEMIZ_TABLO_DIZIN", os.path.join(str(self.KAYNAK_DIZIN), "TemizTablo")))
        self.TEMIZ_KAYNAKCA_DIZIN = Path(os.getenv("TEMIZ_KAYNAKCA_DIZIN", os.path.join(str(self.KAYNAK_DIZIN), "TemizKaynakca")))
        self.PDF_DIR = Path(os.getenv("PDF_DIR", str(self.SUCCESS_DIR) + "/pdfler"))
        self.EMBEDDING_PARCA_DIR = Path(os.getenv("EMBEDDING_PARCA_DIZIN", str(self.SUCCESS_DIR) + "/embedingparca"))
        self.CITATIONS_DIR = Path(os.getenv("CITATIONS_DIR", r"C:\Users\mete\Zotero\zotasistan\citations"))
        self.TABLES_DIR = Path(os.getenv("TABLES_DIR", os.path.join(str(self.KAYNAK_DIZIN), "TemizTablo")))
        self.CHROMA_DB_PATH = os.getenv("CHROMA_DB_PATH", r"C:\Users\mete\Zotero\zotasistan\chroma_db")

        # API AyarlarÄ±
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your_openai_api_key")
        self.ZOTERO_API_KEY = os.getenv("ZOTERO_API_KEY", "your_zotero_api_key")
        self.ZOTERO_USER_ID = os.getenv("ZOTERO_USER_ID", "your_zotero_user_id")
        self.ZOTERO_API_URL = f"https://api.zotero.org/users/{self.ZOTERO_USER_ID}/items"

        # PDF Ä°ÅŸleme AyarlarÄ±
        self.PDF_TEXT_EXTRACTION_METHOD = os.getenv("PDF_TEXT_EXTRACTION_METHOD", "pdfplumber").lower()
        self.TABLE_EXTRACTION_METHOD = os.getenv("TABLE_EXTRACTION_METHOD", "pymupdf").lower()
        self.COLUMN_DETECTION = os.getenv("COLUMN_DETECTION", "True").lower() == "true"

        # Embedding & NLP AyarlarÄ±
        self.EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")
        self.CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "256"))
        self.PARAGRAPH_BASED_SPLIT = os.getenv("PARAGRAPH_BASED_SPLIT", "True").lower() == "true"
        self.MULTI_PROCESSING = os.getenv("MULTI_PROCESSING", "True").lower() == "true"
        self.MAX_WORKERS = int(os.getenv("MAX_WORKERS", "4"))

        # Citation Mapping & Analiz AyarlarÄ±
        self.ENABLE_CITATION_MAPPING = os.getenv("ENABLE_CITATION_MAPPING", "True").lower() == "true"
        self.ENABLE_TABLE_EXTRACTION = os.getenv("ENABLE_TABLE_EXTRACTION", "True").lower() == "true"
        self.ENABLE_CLUSTERING = os.getenv("ENABLE_CLUSTERING", "True").lower() == "true"

        # Loglama & Debug AyarlarÄ±
        self.LOG_LEVEL = os.getenv("LOG_LEVEL", "DEBUG")
        self.ENABLE_ERROR_LOGGING = os.getenv("ENABLE_ERROR_LOGGING", "True").lower() == "true"
        self.DEBUG_MODE = os.getenv("DEBUG_MODE", "False").lower() == "true"

        # Ã‡alÄ±ÅŸma Modu SeÃ§imi
        self.RUN_MODE = os.getenv("RUN_MODE", os.getenv("runGUI", "gui")).lower()

        # VeritabanÄ± AyarlarÄ± (SQLite ve Redis)
        self.USE_SQLITE = os.getenv("USE_SQLITE", "True").lower() == "true"
        self.SQLITE_DB_PATH = os.getenv("SQLITE_DB_PATH", str(self.SUCCESS_DIR) + "/database.db")
        self.REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
        self.REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))

        # Layout Detection YÃ¶ntemi
        self.LAYOUT_DETECTION_METHOD = os.getenv("LAYOUT_DETECTION_METHOD", "regex").lower()
        # Alternatifler: regex, pymupdf, layoutparser, detectron2

        # Gerekli dizinleri oluÅŸtur
        self.ensure_directories()

        # Loglama sistemini baÅŸlat
        self.setup_logging()

        # ChromaDB baÄŸlantÄ±sÄ±nÄ± oluÅŸtur
        self.chroma_client = chromadb.PersistentClient(path=self.CHROMA_DB_PATH)

    def ensure_directories(self):
        directories = [
            self.PDF_DIR,
            self.EMBEDDING_PARCA_DIR,
            self.HEDEF_DIZIN,
            self.TEMIZ_TABLO_DIZIN,
            self.TEMIZ_KAYNAKCA_DIZIN,
            self.CITATIONS_DIR,
            self.TABLES_DIR,
        ]
        for directory in directories:
            if not directory.exists():
                try:
                    directory.mkdir(parents=True, exist_ok=True)
                    self.logger.info(f"âœ… {directory} dizini oluÅŸturuldu.")
                except Exception as e:
                    self.logger.error(f"âŒ {directory} dizini oluÅŸturulamadÄ±: {e}")

    def setup_logging(self):
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'bold_red',
            }
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("pdf_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(getattr(logging, self.LOG_LEVEL.upper(), logging.DEBUG))
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)

    def get_env_variable(self, var_name, default=None):
        return os.getenv(var_name, default)

    def get_max_workers(self):
        return self.MAX_WORKERS

# Global configuration object
config = Config()

#------
# pdfprocessing_module.py
#------

import pdfplumber
import fitz  # PyMuPDF
import pdfminer
import layoutparser as lp
import re
import os
from configmodule import config

class PDFProcessor:
    def __init__(self):
        self.text_extraction_method = config.PDF_TEXT_EXTRACTION_METHOD
        self.table_extraction_method = config.TABLE_EXTRACTION_METHOD
        self.layout_detection_method = config.LAYOUT_DETECTION_METHOD

    def extract_text_from_pdf(self, pdf_path):
        """
        PDF'den metin Ã§Ä±karma iÅŸlemi. KullanÄ±cÄ± tarafÄ±ndan belirlenen yÃ¶nteme gÃ¶re Ã§alÄ±ÅŸÄ±r.
        VarsayÄ±lan: pdfplumber, Alternatifler: pdfminer, pymupdf
        """
        if self.text_extraction_method == "pdfplumber":
            return self._extract_text_pdfplumber(pdf_path)
        elif self.text_extraction_method == "pdfminer":
            return self._extract_text_pdfminer(pdf_path)
        elif self.text_extraction_method == "pymupdf":
            return self._extract_text_pymupdf(pdf_path)
        else:
            raise ValueError(f"Bilinmeyen metin Ã§Ä±karma yÃ¶ntemi: {self.text_extraction_method}")

    def _extract_text_pdfplumber(self, pdf_path):
        with pdfplumber.open(pdf_path) as pdf:
            text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])
        return text

    def _extract_text_pdfminer(self, pdf_path):
        # PDFMiner ile metin Ã§Ä±karma iÅŸlemi
        pass  # GeliÅŸtirilecek

    def _extract_text_pymupdf(self, pdf_path):
        doc = fitz.open(pdf_path)
        text = "\n".join([page.get_text("text") for page in doc])
        return text

    def extract_tables_from_pdf(self, pdf_path):
        """
        PDF'den tablo Ã§Ä±karma iÅŸlemi. KullanÄ±cÄ± tarafÄ±ndan belirlenen yÃ¶nteme gÃ¶re Ã§alÄ±ÅŸÄ±r.
        VarsayÄ±lan: pymupdf, Alternatifler: pdfplumber, pdfminer
        """
        if self.table_extraction_method == "pymupdf":
            return self._extract_tables_pymupdf(pdf_path)
        elif self.table_extraction_method == "pdfplumber":
            return self._extract_tables_pdfplumber(pdf_path)
        elif self.table_extraction_method == "pdfminer":
            return self._extract_tables_pdfminer(pdf_path)
        else:
            raise ValueError(f"Bilinmeyen tablo Ã§Ä±karma yÃ¶ntemi: {self.table_extraction_method}")

    def _extract_tables_pymupdf(self, pdf_path):
        doc = fitz.open(pdf_path)
        tables = []
        for page in doc:
            tables.append(page.find_tables())
        return tables

    def _extract_tables_pdfplumber(self, pdf_path):
        with pdfplumber.open(pdf_path) as pdf:
            tables = [page.extract_table() for page in pdf.pages if page.extract_table()]
        return tables

    def _extract_tables_pdfminer(self, pdf_path):
        # PDFMiner ile tablo Ã§Ä±karma iÅŸlemi
        pass  # GeliÅŸtirilecek

    def detect_layout(self, pdf_path):
        """
        PDF sayfa dÃ¼zenini algÄ±lar. VarsayÄ±lan: regex, Alternatifler: pymupdf, layoutparser, detectron2
        """
        if self.layout_detection_method == "regex":
            return self._detect_layout_regex(pdf_path)
        elif self.layout_detection_method == "pymupdf":
            return self._detect_layout_pymupdf(pdf_path)
        elif self.layout_detection_method == "layoutparser":
            return self._detect_layout_layoutparser(pdf_path)
        elif self.layout_detection_method == "detectron2":
            return self._detect_layout_detectron2(pdf_path)
        else:
            raise ValueError(f"Bilinmeyen layout analiz yÃ¶ntemi: {self.layout_detection_method}")

    def _detect_layout_regex(self, pdf_path):
        text = self.extract_text_from_pdf(pdf_path)
        layout = {"headers": re.findall(r'(?m)^\s*[A-Z][A-Za-z\s]+\s*$', text)}
        return layout

    def _detect_layout_pymupdf(self, pdf_path):
        doc = fitz.open(pdf_path)
        layout = []
        for page in doc:
            layout.append({"page": page.number, "blocks": page.get_text("blocks")})
        return layout

    def _detect_layout_layoutparser(self, pdf_path):
        doc = fitz.open(pdf_path)
        layout = []
        model = lp.Detectron2LayoutModel("lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config")
        for page in doc:
            image = page.get_pixmap()
            detected = model.detect(image)
            layout.append(detected)
        return layout

    def _detect_layout_detectron2(self, pdf_path):
        # Detectron2 ile layout analizi iÅŸlemi
        pass  # GeliÅŸtirilecek

    def reflow_columns(self, text):
        """
        Ã‡ok sÃ¼tunlu makalelerde metni dÃ¼zene sokar ve tek sÃ¼tuna indirger.
        """
        lines = text.split("\n")
        refined_text = []
        for line in lines:
            if len(line.strip()) > 3:
                refined_text.append(line.strip())
        return " ".join(refined_text)


#------
# zotero_module.py
#------

import requests
import json
import os
import redis
import sqlite3
from configmodule import config

class ZoteroModule:
    def __init__(self):
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.api_url = f"https://api.zotero.org/users/{self.user_id}/items"
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH

    def fetch_references_from_zotero(self, query=""):
        """
        Zotero'dan kaynakÃ§a verilerini Ã§eker. Daha Ã¶nce Redis Ã¶nbelleÄŸinde varsa oradan alÄ±r.
        """
        cache_key = f"zotero_refs:{query}"
        cached_data = self.redis_client.get(cache_key)

        if cached_data:
            print("ðŸ“Œ Zotero verileri Redis Ã¶nbelleÄŸinden alÄ±ndÄ±.")
            return json.loads(cached_data)

        headers = {"Zotero-API-Key": self.api_key, "Accept": "application/json"}
        params = {"q": query, "limit": 100}

        response = requests.get(self.api_url, headers=headers, params=params)

        if response.status_code == 200:
            data = response.json()
            self.redis_client.setex(cache_key, 3600, json.dumps(data))  # 1 saatlik Ã¶nbellek
            return data
        else:
            print(f"âŒ Zotero API hatasÄ±: {response.status_code}")
            return None

    def download_pdf_from_doi(self, doi):
        """
        DOI kullanarak PDF indirir. Ã–nce Zotero'dan kontrol eder, yoksa Sci-Hub Ã¼zerinden indirir.
        """
        pdf_path = f"{config.PDF_DIR}/{doi.replace('/', '_')}.pdf"

        if os.path.exists(pdf_path):
            print(f"âœ… PDF zaten mevcut: {pdf_path}")
            return pdf_path

        # Zotero'dan PDF kontrolÃ¼
        zotero_refs = self.fetch_references_from_zotero(doi)
        for ref in zotero_refs:
            if 'links' in ref and 'enclosure' in ref['links']:
                pdf_url = ref['links']['enclosure']['href']
                return self._download_file(pdf_url, pdf_path)

        # Sci-Hub Ã¼zerinden indirme (alternatif)
        sci_hub_url = f"https://sci-hub.se/{doi}"
        return self._download_file(sci_hub_url, pdf_path)

    def _download_file(self, url, save_path):
        """
        Belirtilen URLâ€™den dosya indirir ve kaydeder.
        """
        try:
            response = requests.get(url, stream=True)
            if response.status_code == 200:
                with open(save_path, "wb") as file:
                    for chunk in response.iter_content(chunk_size=8192):
                        file.write(chunk)
                print(f"âœ… PDF indirildi: {save_path}")
                return save_path
        except Exception as e:
            print(f"âŒ PDF indirme hatasÄ±: {e}")
        return None

    def save_references_to_sqlite(self, references):
        """
        Zoteroâ€™dan gelen kaynakÃ§alarÄ± SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS bibliography (
                id TEXT PRIMARY KEY,
                title TEXT,
                authors TEXT,
                year INTEGER,
                citation_key TEXT
            )
        """)

        for ref in references:
            ref_id = ref.get("key", "")
            title = ref.get("data", {}).get("title", "Bilinmeyen BaÅŸlÄ±k")
            authors = ", ".join([author.get("lastName", "") for author in ref.get("data", {}).get("creators", [])])
            year = ref.get("data", {}).get("date", "Bilinmeyen YÄ±l")[:4]
            citation_key = ref.get("data", {}).get("citationKey", "")

            cursor.execute("INSERT OR IGNORE INTO bibliography VALUES (?, ?, ?, ?, ?)", (ref_id, title, authors, year, citation_key))

        conn.commit()
        conn.close()
        print("ðŸ“Œ Zotero kaynakÃ§alarÄ± SQLite veritabanÄ±na kaydedildi.")

    def save_references_to_file(self, references, format="ris"):
        """
        Zotero kaynakÃ§alarÄ±nÄ± RIS veya BibTeX formatÄ±nda kaydeder.
        """
        output_dir = config.TEMIZ_KAYNAKCA_DIZIN
        os.makedirs(output_dir, exist_ok=True)

        file_path = os.path.join(output_dir, f"zotero_references.{format}")
        with open(file_path, "w", encoding="utf-8") as file:
            if format == "ris":
                for ref in references:
                    file.write(self._convert_to_ris(ref))
            elif format == "bib":
                for ref in references:
                    file.write(self._convert_to_bibtex(ref))

        print(f"ðŸ“Œ Zotero kaynakÃ§alarÄ± {format.upper()} formatÄ±nda kaydedildi: {file_path}")

    def _convert_to_ris(self, ref):
        """
        Zotero kaynaÄŸÄ±nÄ± RIS formatÄ±na Ã§evirir.
        """
        ris_template = f"""
        TY  - JOUR
        TI  - {ref.get('data', {}).get('title', '')}
        AU  - {', '.join([author.get("lastName", "") for author in ref.get("data", {}).get("creators", [])])}
        PY  - {ref.get('data', {}).get('date', '')[:4]}
        ID  - {ref.get('key', '')}
        ER  - 
        """
        return ris_template

    def _convert_to_bibtex(self, ref):
        """
        Zotero kaynaÄŸÄ±nÄ± BibTeX formatÄ±na Ã§evirir.
        """
        bib_template = f"""
        @article{{{ref.get('key', '')},
            title={{ {ref.get('data', {}).get('title', '')} }},
            author={{ {', '.join([author.get("lastName", "") for author in ref.get('data', {}).get("creators", [])])} }},
            year={{ {ref.get('data', {}).get('date', '')[:4]} }}
        }}
        """
        return bib_template


# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
zotero_module = ZoteroModule()

#------
# embedding_module.py
#------
import openai
import chromadb
import redis
import sqlite3
import json
import os
from concurrent.futures import ProcessPoolExecutor
from configmodule import config

class EmbeddingModule:
    def __init__(self):
        self.embedding_model = config.EMBEDDING_MODEL
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.max_workers = config.MAX_WORKERS

    def generate_embedding(self, text):
        """
        Belirtilen metin iÃ§in embedding oluÅŸturur. Model, OpenAI veya alternatif olarak seÃ§ilebilir.
        """
        if self.embedding_model == "text-embedding-ada-002":
            return self._generate_embedding_openai(text)
        elif self.embedding_model == "contriever":
            return self._generate_embedding_contriever(text)
        elif self.embedding_model == "specter":
            return self._generate_embedding_specter(text)
        else:
            raise ValueError(f"Bilinmeyen embedding modeli: {self.embedding_model}")

    def _generate_embedding_openai(self, text):
        """
        OpenAI ile embedding oluÅŸturur.
        """
        response = openai.Embedding.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response["data"][0]["embedding"]

    def _generate_embedding_contriever(self, text):
        """
        Contriever modeli ile embedding oluÅŸturur (GeliÅŸtirilecek).
        """
        pass

    def _generate_embedding_specter(self, text):
        """
        Specter modeli ile embedding oluÅŸturur (GeliÅŸtirilecek).
        """
        pass

    def save_embedding_to_chromadb(self, document_id, text):
        """
        Metin embeddingâ€™ini ChromaDBâ€™ye kaydeder.
        """
        embedding = self.generate_embedding(text)
        collection = self.chroma_client.get_collection(name="embeddings")
        collection.add(
            documents=[text],
            metadatas=[{"document_id": document_id}],
            ids=[f"{document_id}"]
        )
        self.redis_client.setex(f"embedding:{document_id}", 3600, json.dumps(embedding))  # Redis Ã¶nbelleÄŸe alma
        self.save_embedding_to_sqlite(document_id, embedding)

    def save_embedding_to_sqlite(self, document_id, embedding):
        """
        Embeddingâ€™i SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS embeddings (
                document_id TEXT PRIMARY KEY,
                embedding TEXT
            )
        """)

        cursor.execute("INSERT OR REPLACE INTO embeddings VALUES (?, ?)", (document_id, json.dumps(embedding)))

        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Embedding SQLite veritabanÄ±na kaydedildi: {document_id}")

    def batch_generate_embeddings(self, texts):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile embedding oluÅŸturma iÅŸlemini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.generate_embedding, texts)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
embedding_module = EmbeddingModule()

#------
# alternative_embeding_module.py
#------ 
import chromadb
import redis
import sqlite3
import json
import os
from sentence_transformers import SentenceTransformer
from concurrent.futures import ProcessPoolExecutor
from configmodule import config

class AlternativeEmbeddingModule:
    def __init__(self):
        self.embedding_model = config.EMBEDDING_MODEL
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.max_workers = config.MAX_WORKERS

        # Alternatif embedding modelleri
        self.models = {
            "contriever": SentenceTransformer("facebook/contriever"),
            "specter": SentenceTransformer("allenai/specter"),
            "minilm": SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        }

    def generate_embedding(self, text):
        """
        Alternatif embedding modelleri ile vektÃ¶r oluÅŸturur.
        """
        if self.embedding_model in self.models:
            model = self.models[self.embedding_model]
            return model.encode(text).tolist()
        else:
            raise ValueError(f"Bilinmeyen embedding modeli: {self.embedding_model}")

    def save_embedding_to_chromadb(self, document_id, text):
        """
        Alternatif embeddingâ€™i ChromaDBâ€™ye kaydeder.
        """
        embedding = self.generate_embedding(text)
        collection = self.chroma_client.get_collection(name="alternative_embeddings")
        collection.add(
            documents=[text],
            metadatas=[{"document_id": document_id}],
            ids=[f"{document_id}"]
        )
        self.redis_client.setex(f"alt_embedding:{document_id}", 3600, json.dumps(embedding))  # Redis Ã¶nbelleÄŸe alma
        self.save_embedding_to_sqlite(document_id, embedding)

    def save_embedding_to_sqlite(self, document_id, embedding):
        """
        Alternatif embeddingâ€™i SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS alternative_embeddings (
                document_id TEXT PRIMARY KEY,
                embedding TEXT
            )
        """)

        cursor.execute("INSERT OR REPLACE INTO alternative_embeddings VALUES (?, ?)", (document_id, json.dumps(embedding)))

        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Alternatif Embedding SQLite veritabanÄ±na kaydedildi: {document_id}")

    def batch_generate_embeddings(self, texts):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile alternatif embedding oluÅŸturma iÅŸlemini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.generate_embedding, texts)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
alternative_embedding_module = AlternativeEmbeddingModule()

#------
# citationmapping_module.py
#------
import re
import json
import sqlite3
import chromadb
import redis
import os
from configmodule import config
from concurrent.futures import ProcessPoolExecutor

class CitationMapping:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.citation_regex = r"\((.*?)\)"  # AtÄ±flarÄ± yakalamak iÃ§in regex
        self.max_workers = config.MAX_WORKERS
        self.citation_dir = config.CITATIONS_DIR

    def extract_references(self, text):
        """
        Ham metindeki atÄ±flarÄ± regex kullanarak tespit eder.
        """
        return re.findall(self.citation_regex, text)

    def map_citations_to_references(self, text, document_id):
        """
        Metindeki atÄ±flarÄ± kaynakÃ§alarla eÅŸleÅŸtirir ve veritabanÄ±na kaydeder.
        """
        atiflar = self.extract_references(text)
        matched_citations = []

        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        for citation in atiflar:
            cursor.execute("SELECT id, title, authors FROM bibliography WHERE citation_key=?", (citation,))
            result = cursor.fetchone()
            if result:
                matched_citations.append({"citation": citation, "source": result})

        conn.close()

        self.save_citations_to_chromadb(document_id, matched_citations)
        self.save_citations_to_sqlite(document_id, matched_citations)
        self.save_citations_to_json(document_id, matched_citations)

        return matched_citations

    def save_citations_to_chromadb(self, document_id, citations):
        """
        EÅŸleÅŸen atÄ±flarÄ± ChromaDB'ye kaydeder.
        """
        collection = self.chroma_client.get_collection(name="citations")
        for match in citations:
            collection.add(
                documents=[match["citation"]],
                metadatas=[{"source": match["source"], "document_id": document_id}],
                ids=[f"{document_id}_{match['source'][0]}"]
            )
        self.redis_client.setex(f"citations:{document_id}", 3600, json.dumps(citations))  # Redis Ã¶nbelleÄŸe alma

    def save_citations_to_sqlite(self, document_id, citations):
        """
        EÅŸleÅŸen atÄ±flarÄ± SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS citation_mappings (
                document_id TEXT,
                citation TEXT,
                source_id TEXT,
                PRIMARY KEY (document_id, citation)
            )
        """)

        for match in citations:
            cursor.execute("INSERT OR IGNORE INTO citation_mappings VALUES (?, ?, ?)", 
                           (document_id, match["citation"], match["source"][0]))

        conn.commit()
        conn.close()
        print(f"ðŸ“Œ AtÄ±f eÅŸleÅŸtirmeleri SQLite veritabanÄ±na kaydedildi: {document_id}")

    def save_citations_to_json(self, document_id, citations):
        """
        Her PDF iÃ§in eÅŸleÅŸen atÄ±flarÄ± JSON formatÄ±nda kaydeder.
        """
        os.makedirs(self.citation_dir, exist_ok=True)
        json_filename = os.path.join(self.citation_dir, f"{document_id}.citations.json")
        
        with open(json_filename, "w", encoding="utf-8") as json_file:
            json.dump(citations, json_file, indent=4, ensure_ascii=False)

        print(f"ðŸ“Œ AtÄ±f eÅŸleÅŸtirmeleri JSON dosyasÄ±na kaydedildi: {json_filename}")

    def batch_process_citations(self, text_document_pairs):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k veri kÃ¼melerinde atÄ±f eÅŸleÅŸtirme sÃ¼recini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(lambda pair: self.map_citations_to_references(pair[0], pair[1]), text_document_pairs)
        return list(results)


# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
citation_mapping = CitationMapping()

#------
# clustering_module.py
#------
import numpy as np
import json
import sqlite3
import redis
import chromadb
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from concurrent.futures import ProcessPoolExecutor
from configmodule import config

class ClusteringModule:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.cluster_algorithm = config.CLUSTERING_ALGORITHM.lower()  # kmeans, dbscan, agglomerative
        self.max_clusters = int(config.MAX_CLUSTERS)
        self.max_workers = config.MAX_WORKERS

    def fetch_embeddings(self):
        """
        ChromaDBâ€™den tÃ¼m embedding verilerini Ã§eker.
        """
        collection = self.chroma_client.get_collection(name="embeddings")
        embeddings = collection.get(include=["documents", "metadatas"])
        vectors = [doc["embedding"] for doc in embeddings]
        document_ids = [doc["metadatas"]["document_id"] for doc in embeddings]
        return np.array(vectors), document_ids

    def cluster_documents(self):
        """
        Belirlenen kÃ¼meleme algoritmasÄ±na gÃ¶re embedding verilerini kÃ¼meler.
        """
        vectors, document_ids = self.fetch_embeddings()

        if self.cluster_algorithm == "kmeans":
            cluster_labels = self._kmeans_clustering(vectors)
        elif self.cluster_algorithm == "dbscan":
            cluster_labels = self._dbscan_clustering(vectors)
        elif self.cluster_algorithm == "agglomerative":
            cluster_labels = self._agglomerative_clustering(vectors)
        else:
            raise ValueError(f"Bilinmeyen kÃ¼meleme algoritmasÄ±: {self.cluster_algorithm}")

        clustered_data = [{"document_id": doc_id, "cluster": cluster} for doc_id, cluster in zip(document_ids, cluster_labels)]
        
        self.save_clusters_to_sqlite(clustered_data)
        self.save_clusters_to_redis(clustered_data)

        return clustered_data

    def _kmeans_clustering(self, vectors):
        """
        K-Means algoritmasÄ± ile kÃ¼meleme yapar.
        """
        model = KMeans(n_clusters=self.max_clusters, random_state=42)
        return model.fit_predict(vectors)

    def _dbscan_clustering(self, vectors):
        """
        DBSCAN algoritmasÄ± ile kÃ¼meleme yapar.
        """
        model = DBSCAN(eps=0.5, min_samples=5)
        return model.fit_predict(vectors)

    def _agglomerative_clustering(self, vectors):
        """
        HiyerarÅŸik kÃ¼meleme (Agglomerative Clustering) yapar.
        """
        model = AgglomerativeClustering(n_clusters=self.max_clusters)
        return model.fit_predict(vectors)

    def save_clusters_to_sqlite(self, clustered_data):
        """
        KÃ¼meleme sonuÃ§larÄ±nÄ± SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_clusters (
                document_id TEXT PRIMARY KEY,
                cluster INTEGER
            )
        """)

        for data in clustered_data:
            cursor.execute("INSERT OR REPLACE INTO document_clusters VALUES (?, ?)", 
                           (data["document_id"], data["cluster"]))

        conn.commit()
        conn.close()
        print("ðŸ“Œ KÃ¼meleme sonuÃ§larÄ± SQLite veritabanÄ±na kaydedildi.")

    def save_clusters_to_redis(self, clustered_data):
        """
        KÃ¼meleme sonuÃ§larÄ±nÄ± Redis Ã¶nbelleÄŸine kaydeder.
        """
        for data in clustered_data:
            self.redis_client.setex(f"cluster:{data['document_id']}", 3600, json.dumps(data))
        print("ðŸ“Œ KÃ¼meleme sonuÃ§larÄ± Redis Ã¶nbelleÄŸine kaydedildi.")

    def batch_cluster_documents(self, document_batches):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k veri kÃ¼melerinde kÃ¼meleme sÃ¼recini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.cluster_documents, document_batches)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
clustering_module = ClusteringModule()

#------
# robust_embeding_module.py
#------
import chromadb
import redis
import sqlite3
import json
import os
import numpy as np
from sentence_transformers import SentenceTransformer
from concurrent.futures import ProcessPoolExecutor
from configmodule import config

class RobustEmbeddingModule:
    def __init__(self):
        self.embedding_model = config.EMBEDDING_MODEL
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.max_workers = config.MAX_WORKERS

        # Alternatif embedding modelleri
        self.models = {
            "bert": SentenceTransformer("bert-base-nli-mean-tokens"),
            "minilm": SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2"),
            "roberta": SentenceTransformer("roberta-base-nli-stsb-mean-tokens")
        }

    def generate_embedding(self, text):
        """
        Hata toleranslÄ± embedding oluÅŸturma iÅŸlemi.
        """
        try:
            if self.embedding_model in self.models:
                model = self.models[self.embedding_model]
                return model.encode(text).tolist()
            else:
                raise ValueError(f"Bilinmeyen embedding modeli: {self.embedding_model}")
        except Exception as e:
            print(f"âŒ Embedding oluÅŸturulamadÄ±: {e}")
            return np.zeros(768).tolist()  # BoÅŸ embedding dÃ¶ndÃ¼r (hata toleransÄ±)

    def save_embedding_to_chromadb(self, document_id, text):
        """
        Embeddingâ€™leri ChromaDBâ€™ye kaydeder.
        """
        embedding = self.generate_embedding(text)
        if embedding:
            collection = self.chroma_client.get_collection(name="robust_embeddings")
            collection.add(
                documents=[text],
                metadatas=[{"document_id": document_id}],
                ids=[f"{document_id}"]
            )
            self.redis_client.setex(f"robust_embedding:{document_id}", 3600, json.dumps(embedding))  # Redis Ã¶nbelleÄŸe alma
            self.save_embedding_to_sqlite(document_id, embedding)

    def save_embedding_to_sqlite(self, document_id, embedding):
        """
        Embeddingâ€™leri SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS robust_embeddings (
                document_id TEXT PRIMARY KEY,
                embedding TEXT
            )
        """)

        cursor.execute("INSERT OR REPLACE INTO robust_embeddings VALUES (?, ?)", (document_id, json.dumps(embedding)))

        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Hata toleranslÄ± embedding SQLite veritabanÄ±na kaydedildi: {document_id}")

    def batch_generate_embeddings(self, texts):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k veri kÃ¼melerinde embedding iÅŸlemini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.generate_embedding, texts)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
robust_embedding_module = RobustEmbeddingModule()

#------
# helper_module.py
#------

import os
import json
import logging
import redis
import re
from configmodule import config
from concurrent.futures import ProcessPoolExecutor

class HelperModule:
    def __init__(self):
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.max_workers = config.MAX_WORKERS

    def clean_text(self, text):
        """
        Metni temizler ve formatlar: gereksiz boÅŸluklarÄ±, Ã¶zel karakterleri kaldÄ±rÄ±r.
        """
        text = re.sub(r"\s+", " ", text)  # Fazla boÅŸluklarÄ± tek boÅŸluÄŸa indir
        text = re.sub(r"[^\w\s.,;!?()]", "", text)  # Ã–zel karakterleri temizle
        return text.strip()

    def normalize_whitespace(self, text):
        """
        Beyaz boÅŸluklarÄ± normalize eder.
        """
        return " ".join(text.split())

    def save_json(self, data, file_path):
        """
        Veriyi JSON formatÄ±nda kaydeder.
        """
        with open(file_path, "w", encoding="utf-8") as json_file:
            json.dump(data, json_file, indent=4, ensure_ascii=False)
        print(f"ðŸ“Œ JSON dosyasÄ± kaydedildi: {file_path}")

    def load_json(self, file_path):
        """
        JSON dosyasÄ±nÄ± okur.
        """
        try:
            with open(file_path, "r", encoding="utf-8") as json_file:
                return json.load(json_file)
        except FileNotFoundError:
            print(f"âŒ Hata: {file_path} bulunamadÄ±!")
            return None

    def cache_data(self, key, data, expiry=3600):
        """
        Redis Ã¶nbelleÄŸe veri kaydeder.
        """
        self.redis_client.setex(key, expiry, json.dumps(data))

    def retrieve_cached_data(self, key):
        """
        Redis Ã¶nbellekten veri alÄ±r.
        """
        cached_data = self.redis_client.get(key)
        return json.loads(cached_data) if cached_data else None

    def batch_process_texts(self, texts):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k metinleri paralel olarak iÅŸler.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.clean_text, texts)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
helper_module = HelperModule()

#------
# file_save_module.py
#------
import os
import json
import sqlite3
import redis
import csv
from configmodule import config
from concurrent.futures import ProcessPoolExecutor

class FileSaveModule:
    def __init__(self):
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.max_workers = config.MAX_WORKERS

        # KlasÃ¶rlerin otomatik oluÅŸturulmasÄ±
        self.directories = {
            "clean_text": config.HEDEF_DIZIN,
            "tables": config.TEMIZ_TABLO_DIZIN,
            "citations": config.CITATIONS_DIR,
            "embeddings": config.EMBEDDING_PARCA_DIR,
            "references": config.TEMIZ_KAYNAKCA_DIZIN
        }
        self.ensure_directories()

    def ensure_directories(self):
        """
        Gerekli klasÃ¶rleri oluÅŸturur.
        """
        for key, path in self.directories.items():
            os.makedirs(path, exist_ok=True)
    
    def save_clean_text(self, document_id, text):
        """
        Temiz metni hem TXT hem de JSON formatÄ±nda kaydeder.
        """
        txt_path = os.path.join(self.directories["clean_text"], f"{document_id}.clean.txt")
        json_path = os.path.join(self.directories["clean_text"], f"{document_id}.clean.json")

        with open(txt_path, "w", encoding="utf-8") as txt_file:
            txt_file.write(text)

        with open(json_path, "w", encoding="utf-8") as json_file:
            json.dump({"document_id": document_id, "text": text}, json_file, indent=4, ensure_ascii=False)

        print(f"ðŸ“Œ Temiz metin kaydedildi: {txt_path} ve {json_path}")

    def save_clean_text_to_sqlite(self, document_id, text):
        """
        Temiz metni SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS clean_texts (
                document_id TEXT PRIMARY KEY,
                text TEXT
            )
        """)

        cursor.execute("INSERT OR REPLACE INTO clean_texts VALUES (?, ?)", (document_id, text))

        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Temiz metin SQLite veritabanÄ±na kaydedildi: {document_id}")

    def save_tables(self, document_id, tables):
        """
        Ã‡Ä±karÄ±lan tablolarÄ± CSV formatÄ±nda kaydeder.
        """
        csv_path = os.path.join(self.directories["tables"], f"{document_id}.tables.csv")

        with open(csv_path, "w", encoding="utf-8", newline="") as csvfile:
            writer = csv.writer(csvfile)
            for table in tables:
                for row in table:
                    writer.writerow(row)
                writer.writerow([])  # BoÅŸ satÄ±r ile ayrÄ±m yap

        print(f"ðŸ“Œ Tablolar kaydedildi: {csv_path}")

    def save_citations(self, document_id, citations):
        """
        AtÄ±flarÄ± hem JSON hem de SQLite formatÄ±nda kaydeder.
        """
        json_path = os.path.join(self.directories["citations"], f"{document_id}.citations.json")

        with open(json_path, "w", encoding="utf-8") as json_file:
            json.dump(citations, json_file, indent=4, ensure_ascii=False)

        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS citations (
                document_id TEXT,
                citation TEXT,
                PRIMARY KEY (document_id, citation)
            )
        """)

        for citation in citations:
            cursor.execute("INSERT OR IGNORE INTO citations VALUES (?, ?)", (document_id, citation))

        conn.commit()
        conn.close()
        print(f"ðŸ“Œ AtÄ±flar SQLite veritabanÄ±na ve JSON dosyasÄ±na kaydedildi: {document_id}")

    def save_references(self, document_id, references, format="ris"):
        """
        KaynakÃ§alarÄ± belirli formatlarda kaydeder (RIS, BibTeX, CSV, VOS).
        """
        format_map = {
            "ris": ".ris",
            "bib": ".bib",
            "csv": ".csv",
            "vos": ".vos"
        }

        if format not in format_map:
            raise ValueError(f"Bilinmeyen format: {format}")

        file_path = os.path.join(self.directories["references"], f"{document_id}{format_map[format]}")

        with open(file_path, "w", encoding="utf-8") as file:
            if format == "ris":
                for ref in references:
                    file.write(self._convert_to_ris(ref))
            elif format == "bib":
                for ref in references:
                    file.write(self._convert_to_bibtex(ref))
            elif format == "csv":
                writer = csv.writer(file)
                for ref in references:
                    writer.writerow([ref["title"], ref["authors"], ref["year"]])
            elif format == "vos":
                json.dump(references, file, indent=4, ensure_ascii=False)

        print(f"ðŸ“Œ KaynakÃ§alar {format.upper()} formatÄ±nda kaydedildi: {file_path}")

    def _convert_to_ris(self, ref):
        """
        KaynakÃ§ayÄ± RIS formatÄ±na Ã§evirir.
        """
        return f"""
        TY  - JOUR
        TI  - {ref.get('title', '')}
        AU  - {', '.join(ref.get('authors', []))}
        PY  - {ref.get('year', '')}
        ER  - 
        """

    def _convert_to_bibtex(self, ref):
        """
        KaynakÃ§ayÄ± BibTeX formatÄ±na Ã§evirir.
        """
        return f"""
        @article{{{ref.get('title', '').replace(' ', '_')}},
            title={{ {ref.get('title', '')} }},
            author={{ {', '.join(ref.get('authors', []))} }},
            year={{ {ref.get('year', '')} }}
        }}
        """

    def batch_save_texts(self, text_document_pairs):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k veri kÃ¼melerinde temiz metinleri paralel olarak kaydeder.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            executor.map(lambda pair: self.save_clean_text(pair[0], pair[1]), text_document_pairs)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
file_save_module = FileSaveModule()

#------
# redis_cache_module.py
#------
import redis
import json
import time
from configmodule import config

class RedisQueue:
    def __init__(self, queue_name="task_queue"):
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.queue_name = queue_name
        self.retry_attempts = int(config.MAX_RETRY_ATTEMPTS)

    def enqueue_task(self, task_data):
        """
        GÃ¶revi Redis kuyruÄŸuna ekler.
        """
        task_json = json.dumps(task_data)
        self.redis_client.rpush(self.queue_name, task_json)
        print(f"âœ… GÃ¶rev kuyruÄŸa eklendi: {task_data}")

    def dequeue_task(self):
        """
        Kuyruktan bir gÃ¶revi Ã§eker ve Ã§Ã¶zÃ¼mler.
        """
        task_json = self.redis_client.lpop(self.queue_name)
        if task_json:
            task_data = json.loads(task_json)
            print(f"ðŸ”„ Ä°ÅŸlem baÅŸlatÄ±ldÄ±: {task_data}")
            return task_data
        else:
            print("ðŸ“­ Kuyruk boÅŸ.")
            return None

    def retry_failed_tasks(self):
        """
        BaÅŸarÄ±sÄ±z olan gÃ¶revleri tekrar kuyruÄŸa ekler.
        """
        failed_queue = f"{self.queue_name}_failed"
        while self.redis_client.llen(failed_queue) > 0:
            task_json = self.redis_client.lpop(failed_queue)
            task_data = json.loads(task_json)
            attempts = task_data.get("attempts", 0)

            if attempts < self.retry_attempts:
                task_data["attempts"] = attempts + 1
                self.enqueue_task(task_data)
                print(f"â™»ï¸ GÃ¶rev yeniden kuyruÄŸa eklendi (Deneme {attempts+1}): {task_data}")
            else:
                print(f"âŒ GÃ¶rev baÅŸarÄ±sÄ±z oldu ve tekrar deneme sÄ±nÄ±rÄ±na ulaÅŸtÄ±: {task_data}")

    def mark_task_as_failed(self, task_data):
        """
        GÃ¶revi baÅŸarÄ±sÄ±z olarak iÅŸaretler ve yeniden denemek iÃ§in kaydeder.
        """
        task_data["status"] = "failed"
        failed_queue = f"{self.queue_name}_failed"
        self.redis_client.rpush(failed_queue, json.dumps(task_data))
        print(f"âš ï¸ GÃ¶rev baÅŸarÄ±sÄ±z olarak iÅŸaretlendi ve tekrar kuyruÄŸa eklendi: {task_data}")

    def get_queue_length(self):
        """
        KuyruÄŸun mevcut uzunluÄŸunu dÃ¶ndÃ¼rÃ¼r.
        """
        return self.redis_client.llen(self.queue_name)

    def process_tasks(self, task_handler):
        """
        Kuyruktaki gÃ¶revleri alÄ±p iÅŸleyen bir iÅŸlem dÃ¶ngÃ¼sÃ¼.
        """
        while True:
            task_data = self.dequeue_task()
            if task_data:
                try:
                    task_handler(task_data)
                except Exception as e:
                    print(f"âŒ GÃ¶rev iÅŸlenirken hata oluÅŸtu: {e}")
                    self.mark_task_as_failed(task_data)
            else:
                print("â³ Yeni gÃ¶rev bekleniyor...")
                time.sleep(5)  # Bekleme sÃ¼resi

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
redis_queue = RedisQueue()

#------
# redis_cache_module.py
#------
import redis
import json
from configmodule import config

class RedisCache:
    def __init__(self):
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.default_expiry = int(config.REDIS_CACHE_EXPIRY)  # VarsayÄ±lan Ã¶nbellek sÃ¼resi (saniye)

    def cache_embedding(self, document_id, embedding):
        """
        Embedding verisini Redis Ã¶nbelleÄŸe kaydeder.
        """
        key = f"embedding:{document_id}"
        self.redis_client.setex(key, self.default_expiry, json.dumps(embedding))
        print(f"âœ… Embedding Redis Ã¶nbelleÄŸe alÄ±ndÄ±: {document_id}")

    def get_cached_embedding(self, document_id):
        """
        Redis'ten embedding verisini getirir.
        """
        key = f"embedding:{document_id}"
        cached_data = self.redis_client.get(key)
        return json.loads(cached_data) if cached_data else None

    def cache_map_data(self, document_id, map_data, map_type="structural"):
        """
        YapÄ±sal veya bilimsel haritalama verisini Redis Ã¶nbelleÄŸe kaydeder.
        """
        key = f"{map_type}_map:{document_id}"
        self.redis_client.setex(key, self.default_expiry, json.dumps(map_data))
        print(f"âœ… {map_type.capitalize()} harita Redis Ã¶nbelleÄŸe kaydedildi: {document_id}")

    def get_cached_map(self, document_id, map_type="structural"):
        """
        Redis'ten yapÄ±sal veya bilimsel harita verisini getirir.
        """
        key = f"{map_type}_map:{document_id}"
        cached_data = self.redis_client.get(key)
        return json.loads(cached_data) if cached_data else None

    def cache_citation(self, document_id, citation_data):
        """
        AtÄ±f verisini Redis Ã¶nbelleÄŸe kaydeder.
        """
        key = f"citation:{document_id}"
        self.redis_client.setex(key, self.default_expiry, json.dumps(citation_data))
        print(f"âœ… AtÄ±f verisi Redis Ã¶nbelleÄŸe kaydedildi: {document_id}")

    def get_cached_citation(self, document_id):
        """
        Redis'ten atÄ±f verisini getirir.
        """
        key = f"citation:{document_id}"
        cached_data = self.redis_client.get(key)
        return json.loads(cached_data) if cached_data else None

    def clear_cache(self, pattern="*"):
        """
        Redis Ã¶nbelleÄŸini belirli bir desen ile temizler.
        """
        keys = self.redis_client.keys(pattern)
        for key in keys:
            self.redis_client.delete(key)
        print(f"ðŸ—‘ï¸ Redis Ã¶nbelleÄŸi temizlendi: {pattern}")

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
redis_cache = RedisCache()

#------
#redis_process_module.py
#------
import redis
import json
import sqlite3
import json

# Redis baÄŸlantÄ±sÄ±

redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)

def add_citation_to_redis(citation_data, citation_id):
    """
    Citation verisini Redis'e ekler.
    citation_data: Citation verisi (JSON formatÄ±nda)
    citation_id: Citation ID
    """
    redis_client.set(f'citation:{citation_id}', json.dumps(citation_data))

def get_citation_from_redis(citation_id):
    """
    Citation verisini Redis'ten Ã§eker.
    citation_id: Citation ID
    """
    citation_json = redis_client.get(f'citation:{citation_id}')
    if citation_json:
        return json.loads(citation_json)
    return None

# import sqlite3
# import json

# SQLite baÄŸlantÄ±sÄ±
conn = sqlite3.connect('citations.db')
cursor = conn.cursor()

# Citation JSON verilerini SQLite tablosuna ekleme
def create_citation_table():
    """
    Citation JSON verilerini saklamak iÃ§in SQLite tablosu oluÅŸturur.
    """
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS citation_json (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        citation_id TEXT NOT NULL,
        citation_data TEXT NOT NULL
    );
    ''')
    conn.commit()

def add_citation_to_sqlite(citation_id, citation_data):
    """
    Citation verisini SQLite veri tabanÄ±na ekler.
    citation_id: Citation ID
    citation_data: Citation verisi (JSON formatÄ±nda)
    """
    cursor.execute('''
    INSERT INTO citation_json (citation_id, citation_data)
    VALUES (?, ?)
    ''', (citation_id, json.dumps(citation_data)))
    conn.commit()

def get_citation_from_sqlite(citation_id):
    """
    Citation verisini SQLite veri tabanÄ±ndan Ã§eker.
    citation_id: Citation ID
    """
    cursor.execute('''
    SELECT citation_data FROM citation_json WHERE citation_id = ?
    ''', (citation_id,))
    row = cursor.fetchone()
    if row:
        return json.loads(row[0])
    return None

def process_and_store_citation(citation_id, citation_data):
    """
    Citation verisini hem Redis'e ekler hem de SQLite'ta saklar.
    citation_id: Citation ID
    citation_data: Citation verisi (JSON formatÄ±nda)
    """
    # Citation verisini Redis'e ekle
    add_citation_to_redis(citation_data, citation_id)

    # Citation verisini SQLite'a ekle
    add_citation_to_sqlite(citation_id, citation_data)import redis
import json

# Redis baÄŸlantÄ±sÄ±
redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)

def add_citation_to_redis(citation_data, citation_id):
    """
    Citation verisini Redis'e ekler.
    citation_data: Citation verisi (JSON formatÄ±nda)
    citation_id: Citation ID
    """
    redis_client.set(f'citation:{citation_id}', json.dumps(citation_data))

def get_citation_from_redis(citation_id):
    """
    Citation verisini Redis'ten Ã§eker.
    citation_id: Citation ID
    """
    citation_json = redis_client.get(f'citation:{citation_id}')
    if citation_json:
        return json.loads(citation_json)
    return None

import sqlite3
import json

# SQLite baÄŸlantÄ±sÄ±
conn = sqlite3.connect('citations.db')
cursor = conn.cursor()

# Citation JSON verilerini SQLite tablosuna ekleme
def create_citation_table():
    """
    Citation JSON verilerini saklamak iÃ§in SQLite tablosu oluÅŸturur.
    """
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS citation_json (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        citation_id TEXT NOT NULL,
        citation_data TEXT NOT NULL
    );
    ''')
    conn.commit()

def add_citation_to_sqlite(citation_id, citation_data):
    """
    Citation verisini SQLite veri tabanÄ±na ekler.
    citation_id: Citation ID
    citation_data: Citation verisi (JSON formatÄ±nda)
    """
    cursor.execute('''
    INSERT INTO citation_json (citation_id, citation_data)
    VALUES (?, ?)
    ''', (citation_id, json.dumps(citation_data)))
    conn.commit()

def get_citation_from_sqlite(citation_id):
    """
    Citation verisini SQLite veri tabanÄ±ndan Ã§eker.
    citation_id: Citation ID
    """
    cursor.execute('''
    SELECT citation_data FROM citation_json WHERE citation_id = ?
    ''', (citation_id,))
    row = cursor.fetchone()
    if row:
        return json.loads(row[0])
    return None

def process_and_store_citation(citation_id, citation_data):
    """
    Citation verisini hem Redis'e ekler hem de SQLite'ta saklar.
    citation_id: Citation ID
    citation_data: Citation verisi (JSON formatÄ±nda)
    """
    # Citation verisini Redis'e ekle
    add_citation_to_redis(citation_data, citation_id)

    # Citation verisini SQLite'a ekle
    add_citation_to_sqlite(citation_id, citation_data)

    # Citation verisini Redis'ten Ã§ek
    retrieved_citation = get_citation_from_redis(citation_id)
#------
# sqlite_storage.py
#------

import sqlite3
import json
import os
from configmodule import config

class SQLiteStorage:
    def __init__(self):
        self.db_path = config.SQLITE_DB_PATH
        self.ensure_tables()

    def ensure_tables(self):
        """
        Gerekli tablolarÄ±n oluÅŸturulmasÄ±nÄ± saÄŸlar.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS clean_texts (
                document_id TEXT PRIMARY KEY,
                text TEXT
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS embeddings (
                document_id TEXT PRIMARY KEY,
                embedding TEXT
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS bibliography (
                id TEXT PRIMARY KEY,
                title TEXT,
                authors TEXT,
                year INTEGER,
                citation_key TEXT
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS citations (
                document_id TEXT,
                citation TEXT,
                PRIMARY KEY (document_id, citation)
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_clusters (
                document_id TEXT PRIMARY KEY,
                cluster INTEGER
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_maps (
                document_id TEXT PRIMARY KEY,
                structural_map TEXT,
                scientific_map TEXT
            )
        """)

        conn.commit()
        conn.close()
        print("âœ… SQLite tablolarÄ± oluÅŸturuldu veya zaten mevcut.")

    def store_clean_text(self, document_id, text):
        """
        Temiz metni SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT OR REPLACE INTO clean_texts VALUES (?, ?)", (document_id, text))
        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Temiz metin kaydedildi: {document_id}")

    def store_embedding(self, document_id, embedding):
        """
        Embedding verisini SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT OR REPLACE INTO embeddings VALUES (?, ?)", (document_id, json.dumps(embedding)))
        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Embedding SQLite veritabanÄ±na kaydedildi: {document_id}")

    def store_bibliography(self, bibliography_data):
        """
        Zotero'dan gelen kaynakÃ§a verilerini SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        for ref in bibliography_data:
            cursor.execute("INSERT OR IGNORE INTO bibliography VALUES (?, ?, ?, ?, ?)",
                           (ref["id"], ref["title"], ", ".join(ref["authors"]), ref["year"], ref["citation_key"]))
        conn.commit()
        conn.close()
        print("ðŸ“Œ KaynakÃ§a SQLite veritabanÄ±na kaydedildi.")

    def store_citation(self, document_id, citations):
        """
        AtÄ±flarÄ± SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        for citation in citations:
            cursor.execute("INSERT OR IGNORE INTO citations VALUES (?, ?)", (document_id, citation))
        conn.commit()
        conn.close()
        print(f"ðŸ“Œ AtÄ±flar SQLite veritabanÄ±na kaydedildi: {document_id}")

    def store_document_cluster(self, document_id, cluster_label):
        """
        KÃ¼meleme sonuÃ§larÄ±nÄ± SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT OR REPLACE INTO document_clusters VALUES (?, ?)", (document_id, cluster_label))
        conn.commit()
        conn.close()
        print(f"ðŸ“Œ KÃ¼meleme sonucu kaydedildi: {document_id} -> Cluster {cluster_label}")

    def store_document_map(self, document_id, structural_map, scientific_map):
        """
        YapÄ±sal ve bilimsel haritalama verilerini SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT OR REPLACE INTO document_maps VALUES (?, ?, ?)",
                       (document_id, json.dumps(structural_map), json.dumps(scientific_map)))
        conn.commit()
        conn.close()
        print(f"ðŸ“Œ Haritalama verisi kaydedildi: {document_id}")

    def retrieve_text_by_id(self, document_id):
        """
        Belirli bir belgeye ait temiz metni getirir.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT text FROM clean_texts WHERE document_id=?", (document_id,))
        result = cursor.fetchone()
        conn.close()
        return result[0] if result else None

    def retrieve_embedding_by_id(self, document_id):
        """
        Belirli bir belgeye ait embedding verisini getirir.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT embedding FROM embeddings WHERE document_id=?", (document_id,))
        result = cursor.fetchone()
        conn.close()
        return json.loads(result[0]) if result else None

    def retrieve_bibliography(self):
        """
        TÃ¼m kaynakÃ§a verilerini getirir.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM bibliography")
        result = cursor.fetchall()
        conn.close()
        return result

    def delete_document(self, document_id):
        """
        Belirli bir belgeye ait tÃ¼m verileri veritabanÄ±ndan siler.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        tables = ["clean_texts", "embeddings", "bibliography", "citations", "document_clusters", "document_maps"]
        for table in tables:
            cursor.execute(f"DELETE FROM {table} WHERE document_id=?", (document_id,))
        conn.commit()
        conn.close()
        print(f"ðŸ—‘ï¸ {document_id} verileri SQLite veritabanÄ±ndan silindi.")

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
sqlite_storage = SQLiteStorage()

#------
# veri_isleme_modulu.py
#------

import sqlite3
import json
import redis
import chromadb
from configmodule import config
from concurrent.futures import ProcessPoolExecutor

class CitationAnalysis:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.max_workers = config.MAX_WORKERS

    def fetch_citations(self, document_id):
        """
        Belirtilen makalenin atÄ±f verilerini SQLite veritabanÄ±ndan Ã§eker.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT citation FROM citations WHERE document_id=?", (document_id,))
        citations = [row[0] for row in cursor.fetchall()]
        conn.close()
        return citations

    def analyze_citation_network(self, document_id):
        """
        AtÄ±f zincirini analiz eder ve aÄŸ haritasÄ±nÄ± oluÅŸturur.
        """
        citations = self.fetch_citations(document_id)
        citation_network = {"document_id": document_id, "citations": citations}

        self.save_citation_network_to_chromadb(document_id, citation_network)
        self.save_citation_network_to_sqlite(document_id, citation_network)
        self.save_citation_network_to_json(document_id, citation_network)

        return citation_network

    def save_citation_network_to_chromadb(self, document_id, citation_network):
        """
        AtÄ±f zincirini ChromaDB'ye kaydeder.
        """
        collection = self.chroma_client.get_collection(name="citation_networks")
        collection.add(
            documents=[json.dumps(citation_network)],
            metadatas=[{"document_id": document_id}],
            ids=[document_id]
        )
        self.redis_client.setex(f"citation_network:{document_id}", 3600, json.dumps(citation_network))
        print(f"ðŸ“Œ AtÄ±f aÄŸÄ± ChromaDB'ye kaydedildi: {document_id}")

    def save_citation_network_to_sqlite(self, document_id, citation_network):
        """
        AtÄ±f zincirini SQLite veritabanÄ±na kaydeder.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS citation_networks (
                document_id TEXT PRIMARY KEY,
                citations TEXT
            )
        """)
        cursor.execute("INSERT OR REPLACE INTO citation_networks VALUES (?, ?)",
                       (document_id, json.dumps(citation_network["citations"])))
        conn.commit()
        conn.close()
        print(f"ðŸ“Œ AtÄ±f aÄŸÄ± SQLite veritabanÄ±na kaydedildi: {document_id}")

    def save_citation_network_to_json(self, document_id, citation_network):
        """
        AtÄ±f zincirini JSON formatÄ±nda kaydeder.
        """
        json_path = f"{config.CITATIONS_DIR}/{document_id}.citation_network.json"
        with open(json_path, "w", encoding="utf-8") as json_file:
            json.dump(citation_network, json_file, indent=4, ensure_ascii=False)
        print(f"ðŸ“Œ AtÄ±f aÄŸÄ± JSON dosyasÄ±na kaydedildi: {json_path}")

    def batch_analyze_citations(self, document_ids):
        """
        Ã‡oklu iÅŸlem desteÄŸi ile bÃ¼yÃ¼k veri kÃ¼melerinde atÄ±f analizini hÄ±zlandÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = executor.map(self.analyze_citation_network, document_ids)
        return list(results)

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
citation_analysis = CitationAnalysis()

#------
# veri gorsellestirme_modulu.py
#------
import sqlite3
import json
import networkx as nx
import matplotlib.pyplot as plt
from configmodule import config

class DataVisualization:
    def __init__(self):
        self.sqlite_db = config.SQLITE_DB_PATH

    def fetch_citation_network(self):
        """
        SQLite veritabanÄ±ndan atÄ±f aÄŸÄ±nÄ± Ã§eker.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT document_id, citations FROM citation_networks")
        rows = cursor.fetchall()
        conn.close()

        citation_graph = {}
        for row in rows:
            document_id = row[0]
            citations = json.loads(row[1])
            citation_graph[document_id] = citations

        return citation_graph

    def plot_citation_network(self):
        """
        AtÄ±f aÄŸÄ±nÄ± grafik olarak Ã§izer.
        """
        citation_graph = self.fetch_citation_network()
        G = nx.DiGraph()

        for doc, citations in citation_graph.items():
            for cited_doc in citations:
                G.add_edge(doc, cited_doc)

        plt.figure(figsize=(10, 7))
        pos = nx.spring_layout(G)
        nx.draw(G, pos, with_labels=True, node_size=2000, node_color="lightblue", edge_color="gray", font_size=10)
        plt.title("AtÄ±f AÄŸÄ± GrafiÄŸi")
        plt.show()
        print("ðŸ“Œ AtÄ±f aÄŸÄ± Ã§izildi.")

    def fetch_document_clusters(self):
        """
        SQLite veritabanÄ±ndan belge kÃ¼meleme sonuÃ§larÄ±nÄ± Ã§eker.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT document_id, cluster FROM document_clusters")
        rows = cursor.fetchall()
        conn.close()

        cluster_data = {}
        for row in rows:
            document_id, cluster = row
            cluster_data[document_id] = cluster

        return cluster_data

    def plot_document_clusters(self):
        """
        KÃ¼meleme sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirir.
        """
        cluster_data = self.fetch_document_clusters()
        unique_clusters = list(set(cluster_data.values()))

        cluster_colors = plt.cm.rainbow([i / len(unique_clusters) for i in range(len(unique_clusters))])

        plt.figure(figsize=(10, 6))
        for idx, (doc, cluster) in enumerate(cluster_data.items()):
            plt.scatter(idx, cluster, color=cluster_colors[cluster], label=f"KÃ¼me {cluster}" if cluster not in plt.gca().get_legend_handles_labels()[1] else "")

        plt.xlabel("Belge Index")
        plt.ylabel("KÃ¼me NumarasÄ±")
        plt.title("Belge KÃ¼meleme GrafiÄŸi")
        plt.legend()
        plt.show()
        print("ðŸ“Œ KÃ¼meleme grafiÄŸi oluÅŸturuldu.")

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
data_visualization = DataVisualization()

#------
# yapay_zeka_finetuning_modulu.py
#------

import os
import json
import sqlite3
import redis
import torch
import transformers
from torch.utils.data import Dataset, DataLoader
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments
from configmodule import config

class FineTuningDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt"
        )
        encoding = {key: val.squeeze() for key, val in encoding.items()}
        encoding["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return encoding

class FineTuner:
    def __init__(self):
        self.model_name = config.FINETUNE_MODEL
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR
        self.output_dir = config.FINETUNE_OUTPUT_DIR

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)

        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)

    def fetch_training_data(self):
        """
        SQLite veritabanÄ±ndan eÄŸitim verisini Ã§eker.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT text, label FROM training_data")
        rows = cursor.fetchall()
        conn.close()

        texts = [row[0] for row in rows]
        labels = [row[1] for row in rows]
        return texts, labels

    def train_model(self):
        """
        Modeli fine-tune ederek eÄŸitir.
        """
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch"
        )

        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=dataset,
            tokenizer=self.tokenizer
        )

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        print(f"âœ… Model eÄŸitildi ve {self.output_dir} dizinine kaydedildi.")

    def save_model_to_redis(self):
        """
        EÄŸitilen modeli Redis iÃ§inde saklar.
        """
        with open(os.path.join(self.output_dir, "pytorch_model.bin"), "rb") as f:
            model_data = f.read()
            self.redis_client.set("fine_tuned_model", model_data)
        print("ðŸ“Œ EÄŸitilmiÅŸ model Redis'e kaydedildi.")

    def load_model_from_redis(self):
        """
        Redis'ten modeli alÄ±r ve belleÄŸe yÃ¼kler.
        """
        model_data = self.redis_client.get("fine_tuned_model")
        if model_data:
            with open(os.path.join(self.output_dir, "pytorch_model.bin"), "wb") as f:
                f.write(model_data)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.output_dir)
            print("ðŸ“Œ Model Redisâ€™ten alÄ±ndÄ± ve belleÄŸe yÃ¼klendi.")
        else:
            print("âŒ Redisâ€™te kayÄ±tlÄ± model bulunamadÄ±.")

# ModÃ¼lÃ¼ dÄ±ÅŸarÄ±dan Ã§aÄŸÄ±rmak iÃ§in sÄ±nÄ±f nesnesi
fine_tuner = FineTuner()

#------
# gui_modulu.py
#------
import customtkinter as ctk
import threading
import os
from tkinter import filedialog
from configmodule import config
from pdfprocessing import extract_text_from_pdf
from citationmappingmodule import citation_mapping
from yapay_zeka_finetuning import fine_tuner
from veri_gorsellestirme import data_visualization

class ZapataGUI(ctk.CTk):
    def __init__(self):
        super().__init__()

        self.title("Zapata M6 - Bilimsel Veri Ä°ÅŸleme Sistemi")
        self.geometry("800x600")

        ctk.set_appearance_mode("dark")
        ctk.set_default_color_theme("blue")

        self.create_widgets()

    def create_widgets(self):
        """
        GUI bileÅŸenlerini oluÅŸturur.
        """

        self.label = ctk.CTkLabel(self, text="Zapata M6 - Bilimsel Makale Ä°ÅŸleme", font=("Arial", 18))
        self.label.pack(pady=10)

        self.load_pdf_button = ctk.CTkButton(self, text="ðŸ“‚ PDF YÃ¼kle", command=self.load_pdf)
        self.load_pdf_button.pack(pady=5)

        self.process_pdf_button = ctk.CTkButton(self, text="ðŸ“„ PDF Ä°ÅŸle", command=self.process_pdf, state="disabled")
        self.process_pdf_button.pack(pady=5)

        self.citation_analysis_button = ctk.CTkButton(self, text="ðŸ”— AtÄ±f Analizi", command=self.run_citation_analysis, state="disabled")
        self.citation_analysis_button.pack(pady=5)

        self.train_ai_button = ctk.CTkButton(self, text="ðŸ¤– AI Modeli EÄŸit", command=self.train_ai_model, state="disabled")
        self.train_ai_button.pack(pady=5)

        self.visualize_button = ctk.CTkButton(self, text="ðŸ“Š AtÄ±f HaritasÄ± GÃ¶ster", command=self.show_visualization, state="disabled")
        self.visualize_button.pack(pady=5)

        self.log_text = ctk.CTkTextbox(self, height=10, wrap="word", font=("Arial", 12))
        self.log_text.pack(pady=10, fill="both", expand=True)

    def log_message(self, message):
        """
        Ä°ÅŸlem durumlarÄ±nÄ± GUI Ã¼zerinden gÃ¶sterir.
        """
        self.log_text.insert("end", message + "\n")
        self.log_text.see("end")

    def load_pdf(self):
        """
        KullanÄ±cÄ±nÄ±n PDF dosyasÄ± seÃ§mesini saÄŸlar.
        """
        file_path = filedialog.askopenfilename(filetypes=[("PDF DosyalarÄ±", "*.pdf")])
        if file_path:
            self.selected_pdf = file_path
            self.process_pdf_button.configure(state="normal")
            self.log_message(f"âœ… PDF seÃ§ildi: {file_path}")

    def process_pdf(self):
        """
        SeÃ§ilen PDF'yi iÅŸleme alÄ±r.
        """
        self.log_message("ðŸ”„ PDF iÅŸleniyor...")
        threading.Thread(target=self._process_pdf_thread, daemon=True).start()

    def _process_pdf_thread(self):
        """
        PDF iÅŸleme iÅŸlemini ayrÄ± bir iÅŸ parÃ§acÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        text = extract_text_from_pdf(self.selected_pdf)
        self.log_message("âœ… PDF baÅŸarÄ±yla iÅŸlendi.")
        self.citation_analysis_button.configure(state="normal")

    def run_citation_analysis(self):
        """
        AtÄ±f analizini Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        self.log_message("ðŸ”„ AtÄ±f analizi baÅŸlatÄ±lÄ±yor...")
        threading.Thread(target=self._citation_analysis_thread, daemon=True).start()

    def _citation_analysis_thread(self):
        """
        AtÄ±f analizi iÅŸlemini ayrÄ± bir iÅŸ parÃ§acÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        citation_mapping.map_citations_to_references(self.selected_pdf)
        self.log_message("âœ… AtÄ±f analizi tamamlandÄ±.")
        self.visualize_button.configure(state="normal")

    def train_ai_model(self):
        """
        AI modelini eÄŸitir.
        """
        self.log_message("ðŸ”„ AI modeli eÄŸitiliyor...")
        threading.Thread(target=self._train_ai_thread, daemon=True).start()

    def _train_ai_thread(self):
        """
        Model eÄŸitim iÅŸlemini ayrÄ± bir iÅŸ parÃ§acÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        fine_tuner.train_model()
        self.log_message("âœ… AI modeli eÄŸitildi.")

    def show_visualization(self):
        """
        AtÄ±f haritasÄ±nÄ± gÃ¶sterir.
        """
        self.log_message("ðŸ“Š AtÄ±f haritasÄ± oluÅŸturuluyor...")
        threading.Thread(target=self._visualize_thread, daemon=True).start()

    def _visualize_thread(self):
        """
        GÃ¶rselleÅŸtirme iÅŸlemini ayrÄ± bir iÅŸ parÃ§acÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        data_visualization.plot_citation_network()
        self.log_message("âœ… AtÄ±f haritasÄ± gÃ¶sterildi.")

    def check_redis_status(self):
        """
        Redis kuyruk durumunu kontrol eder ve GUI'de gÃ¶sterir.
        """
        status = redis_client.ping()
        return "Online" if status else "Offline"
    
    def update_gui_status(self):       
        """
        GUI'yi gÃ¼nceller ve Redis kuyruk durumunu gÃ¶sterir.
        """
        status = self.check_redis_status()
        self.status_label.config(text=f"Redis Status: {status}")
        self.after(5000, self.update_gui_status)  # 5 saniyede bir gÃ¼ncelleme yapar

    def create_status_window(self):
        """
        Redis durumu iÃ§in ayrÄ± bir pencere oluÅŸturur.
        """
        self.status_window = ctk.CTkToplevel(self)
        self.status_window.title("Citation Verisi Durumu")

        self.status_label = ctk.CTkLabel(self.status_window, text="Redis Status: Checking...")
        self.status_label.pack()

        # BaÅŸlangÄ±Ã§ta durumu kontrol et
        self.update_gui_status()



# Uygulama baÅŸlatma
if __name__ == "__main__":
    app = ZapataGUI()
    app.mainloop()

#------
#scientific mapping module
#------

# ==============================
# ðŸ“Œ Zapata M6H - scientific_mapping.py
# ðŸ“Œ Bilimsel Haritalama ModÃ¼lÃ¼
# ðŸ“Œ Ã–zet, giriÅŸ, yÃ¶ntem, sonuÃ§, kaynakÃ§a gibi bÃ¶lÃ¼mleri tespit eder.
# ==============================

import re
import json
import logging
import colorlog
from configmodule import config

class ScientificMapping:
    def __init__(self):
        """Bilimsel haritalama iÅŸlemleri iÃ§in sÄ±nÄ±f."""
        self.logger = self.setup_logging()
        self.section_patterns = {
            "Ã–zet": r"(?:abstract|Ã¶z(et)?)",
            "GiriÅŸ": r"(?:introduction|giriÅŸ)",
            "YÃ¶ntem": r"(?:methods?|metot|yÃ¶ntem)",
            "Bulgular": r"(?:results?|bulgular)",
            "TartÄ±ÅŸma": r"(?:discussion|tartÄ±ÅŸma)",
            "SonuÃ§": r"(?:conclusion|sonuÃ§)",
            "KaynakÃ§a": r"(?:references?|kaynakÃ§a)"
        }

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'bold_red',
            }
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("scientific_mapping.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

    def extract_headings_and_sections(self, text):
        """Metin iÃ§indeki bilimsel bÃ¶lÃ¼mleri belirler ve haritalar."""
        self.logger.info("ðŸ” Bilimsel bÃ¶lÃ¼mler tespit ediliyor...")
        sections = {}
        lines = text.split("\n")

        for i, line in enumerate(lines):
            for section, pattern in self.section_patterns.items():
                if re.search(pattern, line, re.IGNORECASE):
                    sections[section] = i  # SatÄ±r numarasÄ±nÄ± kaydet
        
        self.logger.info(f"âœ… Bilimsel bÃ¶lÃ¼mler tespit edildi: {list(sections.keys())}")
        return sections

    def map_scientific_sections(self, text):
        """Belirlenen bÃ¶lÃ¼mlerin iÃ§eriÄŸini ayrÄ±ÅŸtÄ±rÄ±r."""
        self.logger.info("ðŸ“Œ Bilimsel bÃ¶lÃ¼mler haritalanÄ±yor...")
        section_map = self.extract_headings_and_sections(text)
        mapped_sections = {}

        lines = text.split("\n")
        sorted_sections = sorted(section_map.items(), key=lambda x: x[1])

        for idx, (section, start_line) in enumerate(sorted_sections):
            end_line = sorted_sections[idx + 1][1] if idx + 1 < len(sorted_sections) else len(lines)
            mapped_sections[section] = "\n".join(lines[start_line:end_line])

        self.logger.info(f"âœ… Bilimsel haritalama tamamlandÄ±: {list(mapped_sections.keys())}")
        return mapped_sections

    def save_mapping_to_json(self, mapping, file_path):
        """Haritalanan bilimsel bÃ¶lÃ¼mleri JSON formatÄ±nda kaydeder."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(mapping, f, ensure_ascii=False, indent=4)
            self.logger.info(f"âœ… Bilimsel harita JSON olarak kaydedildi: {file_path}")
        except Exception as e:
            self.logger.error(f"âŒ JSON kaydetme hatasÄ±: {e}")

# ==============================
# âœ… Test KomutlarÄ±:
if __name__ == "__main__":
    scientific_mapper = ScientificMapping()

    sample_text = """Abstract: This study investigates...
    Introduction: In recent years...
    Methods: The methodology of this study includes...
    Results: The findings suggest...
    Discussion: The results indicate...
    Conclusion: In summary...
    References: [1] Author 2020..."""

    mapped_sections = scientific_mapper.map_scientific_sections(sample_text)
    print("ðŸ“„ Bilimsel BÃ¶lÃ¼mler:", mapped_sections)

    scientific_mapper.save_mapping_to_json(mapped_sections, "scientific_map.json")
    print("âœ… Bilimsel haritalama tamamlandÄ±!")
# ==============================

#------
# layout_module.py
#------
# ==============================
# ðŸ“Œ Zapata M6H - layout_analysis.py
# ðŸ“Œ YapÄ±sal Haritalama ModÃ¼lÃ¼
# ðŸ“Œ Sayfa dÃ¼zeni, sÃ¼tun yapÄ±larÄ±, baÅŸlÄ±k-paragraf ayrÄ±mÄ± analiz edilir.
# ==============================

import re
import json
import logging
import colorlog
from configmodule import config

class LayoutAnalysis:
    def __init__(self):
        """YapÄ±sal haritalama iÅŸlemleri iÃ§in sÄ±nÄ±f."""
        self.logger = self.setup_logging()

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'bold_red',
            }
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("layout_analysis.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

    def detect_headers_and_subsections(self, text):
        """Metindeki baÅŸlÄ±k ve alt baÅŸlÄ±klarÄ± tespit eder."""
        self.logger.info("ðŸ” BaÅŸlÄ±k ve alt baÅŸlÄ±klar tespit ediliyor...")
        headers = re.findall(r"^\s*(\d+\.\d*|\b[A-Z][a-z]+\b):", text, re.MULTILINE)
        self.logger.info(f"âœ… Tespit edilen baÅŸlÄ±klar: {headers}")
        return headers

    def map_document_structure(self, text):
        """Sayfa dÃ¼zenini ve sÃ¼tun yapÄ±sÄ±nÄ± analiz eder."""
        self.logger.info("ðŸ“Œ Sayfa yapÄ±sÄ± haritalanÄ±yor...")
        structure_map = {
            "sÃ¼tun_sayÄ±sÄ±": 1 if "\n\n" in text else 2,
            "paragraf_sayÄ±sÄ±": len(text.split("\n\n")),
            "baÅŸlÄ±klar": self.detect_headers_and_subsections(text)
        }

        self.logger.info("âœ… YapÄ±sal haritalama tamamlandÄ±.")
        return structure_map

    def save_layout_to_json(self, layout, file_path):
        """YapÄ±sal haritalama sonuÃ§larÄ±nÄ± JSON olarak kaydeder."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(layout, f, ensure_ascii=False, indent=4)
            self.logger.info(f"âœ… YapÄ±sal harita JSON olarak kaydedildi: {file_path}")
        except Exception as e:
            self.logger.error(f"âŒ JSON kaydetme hatasÄ±: {e}")

# ==============================
# âœ… Test KomutlarÄ±:
if __name__ == "__main__":
    layout_analyzer = LayoutAnalysis()

    sample_text = """1. GiriÅŸ
    1.1 Problem TanÄ±mÄ±
    1.2 LiteratÃ¼r TaramasÄ±
    2. YÃ¶ntem
    3. Bulgular
    4. SonuÃ§ ve TartÄ±ÅŸma"""

    layout_map = layout_analyzer.map_document_structure(sample_text)
    print("ðŸ“„ YapÄ±sal Harita:", layout_map)

    layout_analyzer.save_layout_to_json(layout_map, "layout_map.json")
    print("âœ… YapÄ±sal haritalama tamamlandÄ±!")
# ==============================
#------
# main.py
#------
import os
import sys
import threading
from configmodule import config
from pdfprocessing import extract_text_from_pdf
from citationmappingmodule import citation_mapping
from yapay_zeka_finetuning import fine_tuner
from redisqueue import redis_queue
from rediscache import redis_cache
from sqlite_storage import sqlite_storage
from guimodule import ZapataGUI

def process_pdf(file_path):
    """
    PDF dosyasÄ±nÄ± iÅŸler ve metni Ã§Ä±kartÄ±r.
    """
    print(f"ðŸ”„ PDF Ä°ÅŸleniyor: {file_path}")
    text = extract_text_from_pdf(file_path)
    sqlite_storage.store_clean_text(os.path.basename(file_path), text)
    print(f"âœ… PDF Ä°ÅŸleme TamamlandÄ±: {file_path}")

def run_citation_analysis(file_path):
    """
    AtÄ±f analizini Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    print(f"ðŸ”„ AtÄ±f Analizi BaÅŸlatÄ±ldÄ±: {file_path}")
    citation_mapping.map_citations_to_references(file_path)
    print(f"âœ… AtÄ±f Analizi TamamlandÄ±: {file_path}")

def train_ai_model():
    """
    AI modelini eÄŸitir.
    """
    print("ðŸ”„ AI Modeli EÄŸitiliyor...")
    fine_tuner.train_model()
    print("âœ… AI Modeli EÄŸitildi.")

def queue_processing_loop():
    """
    Redis kuyruÄŸundan gelen gÃ¶revleri iÅŸler.
    """
    print("ðŸ“Œ Kuyruk Ä°ÅŸlemeye BaÅŸladÄ±...")
    redis_queue.process_tasks(process_pdf)

def main():
    """
    Ana uygulama akÄ±ÅŸÄ±.
    """
    mode = config.RUN_MODE  # .env dosyasÄ±ndan GUI veya Konsol modunu okur

    if mode.lower() == "gui":
        print("ðŸ–¥ï¸ GUI Modu BaÅŸlatÄ±lÄ±yor...")
        app = ZapataGUI()
        app.mainloop()

    elif mode.lower() == "console":
        print("ðŸ’» Konsol Modu BaÅŸlatÄ±lÄ±yor...")
        
        while True:
            print("\nðŸ“Œ Ä°ÅŸlem SeÃ§in:")
            print("1 - PDF Ä°ÅŸle")
            print("2 - AtÄ±f Analizi Yap")
            print("3 - AI Modeli EÄŸit")
            print("4 - KuyruÄŸu BaÅŸlat")
            print("5 - Ã‡Ä±kÄ±ÅŸ")

            choice = input("SeÃ§iminizi girin: ")

            if choice == "1":
                file_path = input("ðŸ“‚ PDF DosyasÄ±nÄ±n Yolunu Girin: ")
                process_pdf(file_path)

            elif choice == "2":
                file_path = input("ðŸ“‚ PDF DosyasÄ±nÄ±n Yolunu Girin: ")
                run_citation_analysis(file_path)

            elif choice == "3":
                train_ai_model()

            elif choice == "4":
                threading.Thread(target=queue_processing_loop, daemon=True).start()

            elif choice == "5":
                print("ðŸš€ Programdan Ã§Ä±kÄ±lÄ±yor...")
                sys.exit()

            else:
                print("âŒ GeÃ§ersiz seÃ§im, tekrar deneyin.")

if __name__ == "__main__":
    main()